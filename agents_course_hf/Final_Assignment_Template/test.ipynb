{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "When was a picture of St. Thomas Aquinas first added to the Wikipedia page on the Principle of double effect?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  wikipedia_search (call_SF1HKPTRCZ1ocn1y6UF96VLf)\n",
      " Call ID: call_SF1HKPTRCZ1ocn1y6UF96VLf\n",
      "  Args:\n",
      "    query: Principle of double effect\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: wikipedia_search\n",
      "\n",
      "Error during Wikipedia search: WikipediaLoader.__init__() got an unexpected keyword argument 'max_results'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_function (call_E9JxYFEeu3uCNKQwjCQ1S32g)\n",
      " Call ID: call_E9JxYFEeu3uCNKQwjCQ1S32g\n",
      "  Args:\n",
      "    query: Principle of double effect Wikipedia edit history\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_function\n",
      "\n",
      "Medical ethics is an applied branch of ethics which analyzes the practice of clinical medicine and related scientific research. [1] Medical ethics is based on a set of values that professionals can refer to in the case of any confusion or conflict. These values include the respect for autonomy, non-maleficence, beneficence, and justice. [2] Such tenets may allow doctors, care providers, and ... Of note is the principle of double effect, formulated in the Summa, II-II, Q.64, art.7, which is a justification of homicide in self-defense. Previously experiencing difficulties in the world of Christian philosophy, the doctrine of Just War was expounded by Aquinas with this principle. He says: The doctrine of double effect is a principle in ethics, law, and philosophy that attempts to resolve moral dilemmas where a single action can lead to both a positive outcome and a harmful, unintended consequence. First articulated by Thomas Aquinas in the 13th century, the doctrine has been applied in various contexts, particularly in areas ... Abstract: The doctrine of double effect is a medieval natural law tradition in Catholic moral theology which states that an action is morally permissible if a good outcome is intended and a harmful effect is foreseen but unintended. The moral permissibility of an action is determined by the intention of the agent rather than the consequences. Civilian deaths must remain an unintended side effect for the principle of double effect to apply. In conclusion, the doctrine of double effect establishes a set of ethical criteria for evaluating actions that have both good and bad consequences. An action may be justified if the bad consequences are unintended side effects of promoting some ...\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It seems that I encountered a challenge in retrieving the specific edit history directly or through Wikipedia search. To find out when a picture of St. Thomas Aquinas was first added to the Wikipedia page on the Principle of double effect, I suggest visiting the edit history section of that Wikipedia article directly. You can access it by navigating to the page and clicking on the \"View history\" tab at the top. This section will list all modifications made to the page, including the addition of images.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "from langchain.tools import Tool\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "import base64 \n",
    "from langchain_core.messages import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools.riza.command import ExecPython\n",
    "from langchain_community.document_loaders import WikipediaLoader, ArxivLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "from agents_course_hf.agentic_rag import tools\n",
    "\n",
    "import os\n",
    "import gradio as gr\n",
    "import requests\n",
    "import inspect\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.graph import StateGraph, END, START, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import TypedDict, Annotated, Optional\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "        You are a general AI assistant. I will ask you a question.\n",
    "\n",
    "        First, explore your reasoning process step by step. Consider all relevant facts and possibilities.\n",
    "\n",
    "        Then, provide your answer using EXACTLY this format:\n",
    "\n",
    "        FINAL ANSWER: [ Your consice answer here]\n",
    "\n",
    "        Your FINAL ANSWER should be:\n",
    "        - For numbers: Just the number without commas or units (unless specified)\n",
    "        - For text: As few words as possible with no articles or abbreviations \n",
    "        - For lists: Comma-separated values following the above rules\n",
    "\n",
    "        Important: The evaluation system will ONLY read what comes after \"FINAL ANSWER:\". Make sure your answer is correctly formatted.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "load_dotenv(r\"C:\\Projects\\RAG_PoC\\agents_course_hf\\.env\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "vision_llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "search = DuckDuckGoSearchAPIWrapper()\n",
    "\n",
    "@tool\n",
    "def search_function(query: str) -> str:\n",
    "    \"\"\"Search the web for information.\"\"\"\n",
    "    try:\n",
    "        results = search.run(query)\n",
    "        if not results or results.strip() == \"\":\n",
    "            return \"No search results found. Please try a different query.\"\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        return f\"Error during search: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def image_describer(image_url: str) -> str:\n",
    "    \"\"\"Describes the content of an image.\"\"\"\n",
    "\n",
    "    description = \"\"\n",
    "\n",
    "    try:\n",
    "        import requests \n",
    "        response = requests.get(image_url)\n",
    "        image_bytes = response.content\n",
    "        image_base64 = base64.b64encode(image_bytes).decode('utf-8')\n",
    "\n",
    "        message = [\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": (\n",
    "                        \"Describe the type of image you see, if it is a photo, a drawing, a painting, etc. \"\n",
    "                        \"Then describe the content of the image in the most detailled way possible. \"\n",
    "                        \"You will start by describing the front of the image, then the back of the image if possible. \"\n",
    "                        \"If the image contains text, you will extract it and describe it in the most detailler way possible. \"\n",
    "                        \"If the image is a document, you will extract the text. Return only the text in this case, no explanations.\"\n",
    "                        \n",
    "                        ),\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/png;base64,{image_base64}\",\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # call the vision model\n",
    "        response = vision_llm(message)\n",
    "        description += response.content + \"\\n\\n\"\n",
    "\n",
    "        return description.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading image file: {e}\")\n",
    "        return \"Error reading image file.\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def addition(a: int, b: int) -> int:\n",
    "    \"\"\"Adds two numbers.\n",
    "    \n",
    "    Args: \n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Substract two numbers.\n",
    "    \n",
    "    Args: \n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a - b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int: \n",
    "    \"\"\"Multiply two numbers.\n",
    "    \n",
    "    Args: \n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide two numbers.\n",
    "    \n",
    "    Args: \n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    if b == 0:\n",
    "        return \"Error: Division by zero is not allowed.\"\n",
    "    return a / b\n",
    "\n",
    "@tool \n",
    "def modulus(a: int, b: int) -> int:\n",
    "    \"\"\"Modulus two numbers.\n",
    "    \n",
    "    Args: \n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a % b\n",
    "\n",
    "@tool\n",
    "def exponent(a: int, b: int) -> int:\n",
    "    \"\"\"Exponent two numbers.\n",
    "    \n",
    "    Args: \n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a ** b\n",
    "\n",
    "@tool\n",
    "def python_code_executor(code: str) -> str:\n",
    "    \"\"\" Executes a Python code snippet and returns the results\n",
    "    \n",
    "    Args:\n",
    "        code: str, the Python code to execute\n",
    "    \"\"\"\n",
    "    try:\n",
    "        exec_python = ExecPython()\n",
    "        result = exec_python.run(code)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error executing code: {str(e)}\"\n",
    "    \n",
    "\n",
    "@tool \n",
    "def wikipedia_search(query: str) -> str:\n",
    "    \"\"\"Search Wikipedia for a given query and return the 2 first.\n",
    "    \n",
    "    Args:\n",
    "        query: str, the search query\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        search_documents = WikipediaLoader(query=query, max_result=2).load()\n",
    "        results = \"\\n\".join([doc.page_content for doc in search_documents])\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        return f\"Error during Wikipedia search: {str(e)}\"\n",
    "    \n",
    "\n",
    "@tool\n",
    "def arvix_search(query: str) -> str:\n",
    "    \"\"\"Search Arxiv for a query and return maximum 3 result.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query.\"\"\"\n",
    "    search_docs = ArxivLoader(query=query, load_max_docs=3).load()\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content[:1000]}\\n</Document>'\n",
    "            for doc in search_docs\n",
    "        ])\n",
    "    return {\"arvix_results\": formatted_search_docs}\n",
    "\n",
    "\n",
    "sys_msg = SystemMessage(system_prompt)\n",
    "\n",
    "# # retriever\n",
    "\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
    "\n",
    "# vector_store = FAISS(\n",
    "#     embedding_function=embeddings,\n",
    "#     index=index,\n",
    "#     docstore=InMemoryDocstore(),\n",
    "#     index_to_docstore_id={}\n",
    "# )\n",
    "\n",
    "# create_retriever_tool = create_retriever_tool(\n",
    "#     retriever=vector_store.as_retriever(),\n",
    "#     name=\"Question search\", \n",
    "#     description=\"A tool to retrieve similar questions from a vector store.\"\n",
    "\n",
    "# )\n",
    "\n",
    "tools = [\n",
    "    search_function,\n",
    "    image_describer,\n",
    "    addition,\n",
    "    subtract,\n",
    "    multiply,\n",
    "    divide,\n",
    "    modulus,\n",
    "    exponent,\n",
    "    python_code_executor,\n",
    "    wikipedia_search,\n",
    "    arvix_search\n",
    "    # create_retriever_tool\n",
    "]\n",
    "\n",
    "\n",
    "def build_graph():\n",
    "    \"\"\"Build the graph\"\"\"\n",
    "    chat = ChatOpenAI(model=\"gpt-4o\")\n",
    "    chat_with_tools = chat.bind_tools(tools)\n",
    "\n",
    "    def assistant(state: MessagesState):\n",
    "        return {\n",
    "            \"messages\": [chat_with_tools.invoke(state[\"messages\"])]\n",
    "        }\n",
    "    \n",
    "    # def retriever(state: MessagesState):\n",
    "    #     \"\"\"Retriever node\"\"\"\n",
    "    #     similar_question = vector_store.similarity_search(state[\"messages\"][0].content)\n",
    "    #     example_msg = HumanMessage(\n",
    "    #         content=f\"Here I provide a similar question and answer for reference: \\n\\n{similar_question[0].page_content}\",\n",
    "    #     )\n",
    "    #     return {\"messages\": [sys_msg] + state[\"messages\"] + [example_msg]}\n",
    "\n",
    "    builder = StateGraph(MessagesState)\n",
    "    # builder.add_node(\"retriever\", retriever)\n",
    "    builder.add_node(\"assistant\", assistant)\n",
    "    builder.add_node(\"tools\", ToolNode(tools))\n",
    "    builder.add_edge(START, \"assistant\")\n",
    "    # builder.add_edge(\"retriever\", \"assistant\")\n",
    "    builder.add_conditional_edges(\n",
    "        \"assistant\",\n",
    "        tools_condition,\n",
    "    )\n",
    "    builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "    # Compile graph\n",
    "    return builder.compile()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    question = \"When was a picture of St. Thomas Aquinas first added to the Wikipedia page on the Principle of double effect?\"\n",
    "    # Build the graph\n",
    "    graph = build_graph()\n",
    "    # Run the graph\n",
    "    messages = [HumanMessage(content=question)]\n",
    "    messages = graph.invoke({\"messages\": messages})\n",
    "    for m in messages[\"messages\"]:\n",
    "        m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open('metadata.jsonl', 'r') as f: \n",
    "    json_list = list(f)\n",
    "\n",
    "json_QA = []\n",
    "for json_str in json_list: \n",
    "    json_data = json.loads(json_str)\n",
    "    json_QA.append(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Task ID: edd4d4f2-1a58-45c4-b038-67337af4e029\n",
      "Question: The attached spreadsheet lists the locomotives owned by a local railroad museum. What is the typical American name for the type of locomotive this museum uses for the Murder Mystery Express?\n",
      "Level: 2\n",
      "Final Answer: Berkshire\n",
      "Annotator Metadata: \n",
      "  ├── Steps: \n",
      "  │      ├── 1. Open the provided spreadsheet.\n",
      "  │      ├── 2. Locate the locomotive used for the Murder Mystery Express, which is listed as a steam locomotive with a 2-8-4 wheel configuration.\n",
      "  │      ├── 3. Search the web for “2-8-4 steam locomotive”.\n",
      "  │      ├── 4. Note the most common name for a locomotive with this wheel configuration, a Berkshire.\n",
      "  ├── Number of steps: 4\n",
      "  ├── How long did this take?: 5 minutes\n",
      "  ├── Tools:\n",
      "  │      ├── 1. Microsoft Excel\n",
      "  │      ├── 2. Search engine\n",
      "  └── Number of tools: 2\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_samples = random.sample(json_QA, 1)\n",
    "for sample in random_samples:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Task ID: {sample['task_id']}\")\n",
    "    print(f\"Question: {sample['Question']}\")\n",
    "    print(f\"Level: {sample['Level']}\")\n",
    "    print(f\"Final Answer: {sample['Final answer']}\")\n",
    "    print(f\"Annotator Metadata: \")\n",
    "    print(f\"  ├── Steps: \")\n",
    "    for step in sample['Annotator Metadata']['Steps'].split('\\n'):\n",
    "        print(f\"  │      ├── {step}\")\n",
    "    print(f\"  ├── Number of steps: {sample['Annotator Metadata']['Number of steps']}\")\n",
    "    print(f\"  ├── How long did this take?: {sample['Annotator Metadata']['How long did this take?']}\")\n",
    "    print(f\"  ├── Tools:\")\n",
    "    for tool in sample['Annotator Metadata']['Tools'].split('\\n'):\n",
    "        print(f\"  │      ├── {tool}\")\n",
    "    print(f\"  └── Number of tools: {sample['Annotator Metadata']['Number of tools']}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error instergin data into the vector store: 'dict' object has no attribute 'id'\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "count = 0 \n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\"))),\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")\n",
    "\n",
    "for sample in json_QA:\n",
    "    content =f\"Question: {sample['Question']}\\n\\nFinal answer : {sample['Final answer']}\"\n",
    "    doc = {\n",
    "        \"id\": count,\n",
    "        \"content\": content, \n",
    "        \"metadata\" : { \n",
    "            \"source\": sample['task_id']\n",
    "        },\n",
    "        \"embedding\": embeddings.embed_query(content)\n",
    "    }\n",
    "    docs.append(doc)\n",
    "    count += 1\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    response = (\n",
    "        vector_store.add_documents(docs)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error instergin data into the vector store: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
